{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import accuracy_score\nimport nltk\nimport re\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom sklearn.model_selection import train_test_split, GridSearchCV","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-09T00:03:02.569940Z","iopub.execute_input":"2023-08-09T00:03:02.570433Z","iopub.status.idle":"2023-08-09T00:03:02.580675Z","shell.execute_reply.started":"2023-08-09T00:03:02.570395Z","shell.execute_reply":"2023-08-09T00:03:02.578700Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"O **Naive Bayes é um algoritmo de classificação probabilística que se baseia no Teorema de Bayes ** e assume uma independência ingênua (daí o \"naive\" em seu nome) entre os recursos (palavras, no caso de textos) para simplificar o cálculo das probabilidades. Ele é amplamente usado em tarefas de processamento de linguagem natural, como classificação de texto.","metadata":{}},{"cell_type":"markdown","source":"**O teorema de Bayes é uma fórmula matemática que nos permite calcular a probabilidade de um evento ocorrer**, dado que outro evento já ocorreu\nP(A | B) = P(B | A) * P(A) / P(B)\n\nP(A | B) é a probabilidade do evento A ocorrer, dado que o evento B já ocorreu.\n\nP(B | A) é a probabilidade do evento B ocorrer, dado que o evento A já ocorreu.\n\nP(A) e P(B) são as probabilidades dos eventos A e B ocorrerem, respectivamente.","metadata":{}},{"cell_type":"markdown","source":"Podemos usar esse algoritimo para análisar se o conjunto de twites desse Dataset\nTrata-se de mensagens sobre a mudânça climática. Para tanto separamos as mensagens em\n\npró - Políticas de enfrentamento as mudâças climáticas\n\nanti - Políticas de enfrentamento as mudâças climáticas\n\nneutro - Políticas de enfrentamento as mudâças climáticas\n\nOu se trata-se de uma Fake News","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('../input/twitter-climate-change-sentiment-dataset/twitter_sentiment_data.csv')","metadata":{"execution":{"iopub.status.busy":"2023-08-08T23:30:31.138258Z","iopub.execute_input":"2023-08-08T23:30:31.139264Z","iopub.status.idle":"2023-08-08T23:30:31.372941Z","shell.execute_reply.started":"2023-08-08T23:30:31.139215Z","shell.execute_reply":"2023-08-08T23:30:31.371830Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"df.head(8)","metadata":{"execution":{"iopub.status.busy":"2023-08-08T23:30:38.123149Z","iopub.execute_input":"2023-08-08T23:30:38.123555Z","iopub.status.idle":"2023-08-08T23:30:38.150769Z","shell.execute_reply.started":"2023-08-08T23:30:38.123522Z","shell.execute_reply":"2023-08-08T23:30:38.149391Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"   sentiment                                            message  \\\n0         -1  @tiniebeany climate change is an interesting h...   \n1          1  RT @NatGeoChannel: Watch #BeforeTheFlood right...   \n2          1  Fabulous! Leonardo #DiCaprio's film on #climat...   \n3          1  RT @Mick_Fanning: Just watched this amazing do...   \n4          2  RT @cnalive: Pranita Biswasi, a Lutheran from ...   \n5          0  Unamshow awache kujinga na iko global warming ...   \n6          2  RT @cnalive: Pranita Biswasi, a Lutheran from ...   \n7          2  RT @CCIRiviera: Presidential Candidate #Donald...   \n\n              tweetid  \n0  792927353886371840  \n1  793124211518832641  \n2  793124402388832256  \n3  793124635873275904  \n4  793125156185137153  \n5  793125429418815489  \n6  793125430236684289  \n7  793126558688878592  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sentiment</th>\n      <th>message</th>\n      <th>tweetid</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-1</td>\n      <td>@tiniebeany climate change is an interesting h...</td>\n      <td>792927353886371840</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>RT @NatGeoChannel: Watch #BeforeTheFlood right...</td>\n      <td>793124211518832641</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>Fabulous! Leonardo #DiCaprio's film on #climat...</td>\n      <td>793124402388832256</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>RT @Mick_Fanning: Just watched this amazing do...</td>\n      <td>793124635873275904</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2</td>\n      <td>RT @cnalive: Pranita Biswasi, a Lutheran from ...</td>\n      <td>793125156185137153</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0</td>\n      <td>Unamshow awache kujinga na iko global warming ...</td>\n      <td>793125429418815489</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>2</td>\n      <td>RT @cnalive: Pranita Biswasi, a Lutheran from ...</td>\n      <td>793125430236684289</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>2</td>\n      <td>RT @CCIRiviera: Presidential Candidate #Donald...</td>\n      <td>793126558688878592</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"**Pré-processamento de Dados:**\nPrimeiro, é pré-processar os tweets. \n\nPara tanto iremos remover caracteres especiais, pontuações, stopwords (palavras comuns que não trazem muita informação) e a tokenização dos tweets em palavras individuais.","metadata":{}},{"cell_type":"code","source":"# Pré-processamento avançado com remoção de caracteres numéricos e normalização\nnltk.download('stopwords')\nstop_words = set(stopwords.words('english'))\nstemmer = PorterStemmer()\n\ndef preprocess_text(text):\n    # Converte para minúsculas\n    text = text.lower()\n    # Remover caracteres numéricos\n    text = re.sub(r'\\d+', '', text)\n    # Remover URLs e emojis\n    text = re.sub(r'http\\S+|www.\\S+|@[A-Za-z0-9]+', '', text)\n    text = re.sub('[^\\w\\s#@/:%.,_-]', '', text, flags=re.UNICODE)\n    # Remover stopwords\n    words = text.split()\n    filtered_words = [word for word in words if word not in stop_words]\n    # Stemming\n    stemmed_words = [stemmer.stem(word) for word in filtered_words]\n    return ' '.join(stemmed_words)\n\ndf['message'] = df['message'].apply(preprocess_text)","metadata":{"execution":{"iopub.status.busy":"2023-08-08T23:32:21.903086Z","iopub.execute_input":"2023-08-08T23:32:21.903784Z","iopub.status.idle":"2023-08-08T23:32:40.689827Z","shell.execute_reply.started":"2023-08-08T23:32:21.903747Z","shell.execute_reply":"2023-08-08T23:32:40.688384Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Essa primeira parte** realiza um pré-processamento avançado em um conjunto de mensagens de texto usando a biblioteca NLTK (Natural Language Toolkit) para Python.\n\n**Para tanto a linha nltk.download faz um download de stopwords**, ou seja, palavras comuns que são geralmente removidas durante a análise de texto\n\nUm conjunto de stopwords em inglês é carregado na variável stop_words. \nApós isso, um objeto PorterStemmer é criado, que é usado para reduzir as palavras às suas formas básicas (stems) para tratamento mais eficiente.(melhorar a performânce) \n\n**A partir disso eu crio uma função:\n**\n\n\nEsta função realiza uma série de etapas para pré-processar o texto fornecido:\n\nConverte todo o texto para minúsculas.\n\nRemove caracteres numéricos usando a expressão regular \\d+.\n\nRemove URLs e menções de usuário (emojis) usando expressões regulares.\n\nRemove caracteres especiais usando a expressão regular [^\\w\\s#@/:%.,_-].\n\nDivide o texto em palavras individuais.\n\nRemove as palavras que estão presentes na lista de stopwords.\n\nAplica o processo de stemming a cada palavra para reduzi-las à sua forma base.\n\n\n**Após a criação dessa função temos:\n**\n\n\nA função preprocess_text é aplicada à coluna 'message' de um DataFrame df. (por isso a demora para rodar essa parte do programa)","metadata":{}},{"cell_type":"code","source":"# Outras representações de palavras (TF-IDF)\nvectorizer = TfidfVectorizer()\nX = vectorizer.fit_transform(df['message'])\n\n# Dividir o conjunto de dados em treinamento e teste\nX_train, X_test, y_train, y_test = train_test_split(X, df['sentiment'], test_size=0.2, random_state=42)\n# Balanceamento de classes com SMOTE\nsmote = SMOTE(random_state=42)\nX_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n\n# Ajuste de hiperparâmetros com GridSearchCV\nparams = {'alpha': [0.1, 0.5, 1.0]}\nnaive_bayes_model = MultinomialNB()\ngrid_search = GridSearchCV(naive_bayes_model, params, cv=5, scoring='accuracy')\ngrid_search.fit(X_train_resampled, y_train_resampled)\n\n# Melhor configuração de hiperparâmetros\nbest_alpha = grid_search.best_params_['alpha']\nprint(f'Melhor valor de alpha encontrado: {best_alpha}')\n\n# Treinar o modelo Naive Bayes com a melhor configuração de hiperparâmetros\nnaive_bayes_model = MultinomialNB(alpha=best_alpha)\nnaive_bayes_model.fit(X_train_resampled, y_train_resampled)\n# Avaliar o modelo\ny_pred = naive_bayes_model.predict(X_test)\n\n# Calcular a acurácia\naccuracy = accuracy_score(y_test, y_pred)\nprint(f'Acurácia do modelo Naive Bayes: {accuracy:.2f}')","metadata":{"execution":{"iopub.status.busy":"2023-08-09T00:03:50.300295Z","iopub.execute_input":"2023-08-09T00:03:50.300778Z","iopub.status.idle":"2023-08-09T00:04:00.490581Z","shell.execute_reply.started":"2023-08-09T00:03:50.300735Z","shell.execute_reply":"2023-08-09T00:04:00.489694Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Melhor valor de alpha encontrado: 0.1\nAcurácia do modelo Naive Bayes: 0.65\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Nessa parte do programa continuamos na parte de pré processamento de dados\n\nPara tanto a classe TfidfVectorizer do scikit-learn é usada para converter o texto pré-processado em uma representação numérica usando a **técnica TF-IDF**. cada mensagem é transformada em vetores ponderados\nEsse vetores levam em consideração a frequência das palavras em cada mensagem em relação à frequência inversa nos documentos.\nX agora contém as representações numéricas das mensagens, e y contém os rótulos de sentimento associados.","metadata":{}},{"cell_type":"markdown","source":"**Depois é feito o treinamento:**\n\nos dados são divididos em conjuntos de treinamento e teste usando a função train_test_split do scikit-learn. \n\nDepois é necessário balancear as classes dentro do conjunto de treinamento. Por isso usado o Smote\n\nIsso cria novas instâncias sintéticas das classes minoritárias para equilibrar a distribuição de classes. X_train_resampled e y_train_resampled agora contêm os dados de treinamento balanceados.","metadata":{}},{"cell_type":"markdown","source":"Nesta etapa, um modelo Naive Bayes é usado (especificamente MultinomialNB) e o GridSearchCV é aplicado para ajustar o hiperparâmetro alpha (que controla a suavização) usando validação cruzada. \n\nO parâmetro scoring é definido como 'accuracy' para avaliar o desempenho.","metadata":{}},{"cell_type":"code","source":"# Relatório de classificação\nclass_report = classification_report(y_test, y_pred)\nprint('Relatório de Classificação:')\nprint(class_report)","metadata":{"execution":{"iopub.status.busy":"2023-08-09T00:11:21.561978Z","iopub.execute_input":"2023-08-09T00:11:21.562451Z","iopub.status.idle":"2023-08-09T00:11:21.596366Z","shell.execute_reply.started":"2023-08-09T00:11:21.562416Z","shell.execute_reply":"2023-08-09T00:11:21.594975Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Relatório de Classificação:\n              precision    recall  f1-score   support\n\n          -1       0.40      0.60      0.48       784\n           0       0.50      0.51      0.50      1582\n           1       0.80      0.65      0.72      4514\n           2       0.64      0.78      0.70      1909\n\n    accuracy                           0.65      8789\n   macro avg       0.59      0.64      0.60      8789\nweighted avg       0.68      0.65      0.66      8789\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Com isso imprimimos o melhor alpha** e a partir disso novo modelo Naive Bayes é treinado usando a melhor configuração de hiperparâmetros encontrada durante o GridSearchCV","metadata":{}},{"cell_type":"markdown","source":"O relatório de classificação fornecerá métricas como precisão, recall e F1-score para cada classe de sentimento \n(por exemplo, \"falso\" ou \"verdadeiro\"), \n\nAjudando a entender como o modelo está performando para cada classe separadamente","metadata":{}},{"cell_type":"markdown","source":"Temos que:\n\n**precision (precisão):** a precisão para cada classe indica quantas das mensagens classificadas como essa classe realmente pertencem a essa classe.\n\n**recall (revocação)**: o recall para cada classe indica quantas das mensagens reais dessa classe foram corretamente identificadas pelo modelo.\n\n**f1-score:** O f1-score é a média harmônica entre a precisão e o recall. Ele oferece uma métrica equilibrada que leva em consideração tanto falsos positivos quanto falsos negativos. É especialmente útil quando você tem classes desbalanceadas.\n\n**support**: O suporte indica o número de instâncias reais de cada classe no conjunto de teste.\n\n**accuracy (acurácia):** A acurácia é a proporção total de previsões corretas em relação ao total de instâncias. No caso 0.65.\n\n**macro avg e weighted avg:** Essas linhas fornecem médias das métricas para todas as classes. A média ponderada (weighted avg) dá mais peso às classes maiores (com base no suporte), enquanto a média não ponderada (macro avg) trata todas as classes igualmente.","metadata":{}},{"cell_type":"markdown","source":"Com isso:\n\nO modelo tem desempenho variado para cada classe. Ele é mais preciso e tem recall mais alto para a classe 1, o que indica que está lidando melhor com mensagens que provavelmente contêm informações verdadeiras.\nA classe -1 tem a menor precisão, o que sugere que o modelo está fazendo mais falsos positivos (classificando mensagens falsas como verdadeiras).\nA classe 2 tem o recall mais alto, indicando que o modelo está identificando corretamente a maioria das mensagens reais dessa classe.","metadata":{}}]}